{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f35354cd",
   "metadata": {},
   "source": [
    "# Lightweight Fine-Tuning Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560fb3ff",
   "metadata": {},
   "source": [
    "TODO: In this cell, describe your choices for each of the following\n",
    "\n",
    "* PEFT technique: LoRA (Low-Rank Adaptation). LoRA is widely used, easy to implement, and compatible with sequence classification models\n",
    "* Model: GPT-2 (using GPT2ForSequenceClassification). It's small, efficient, and Hugging Face provides all utilities for sequence classification\n",
    "* Evaluation approach: The Hugging Face Trainer’s evaluate method is used for straightforward, replicable evaluations.\n",
    "* Fine-tuning dataset: https://huggingface.co/datasets/dair-ai/emotion\n",
    "The dataset is small, clean, widely used for benchmarking, and contains tweets labeled with six emotions (joy, sadness, anger, fear, love, surprise), making it ideal for quick experiments on limited hardware."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6acb76",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pip install -U datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44866e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8d76bb",
   "metadata": {},
   "source": [
    "## Loading and Evaluating a Foundation Model\n",
    "\n",
    "TODO: In the cells below, load your chosen pre-trained Hugging Face model and evaluate its performance prior to fine-tuning. This step includes loading an appropriate tokenizer and dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0035632",
   "metadata": {},
   "source": [
    "1. Load the Pre-trained Model and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4935cb4d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2ForSequenceClassification\n",
    "\n",
    "# Load and augment the tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "\n",
    "# Load the model\n",
    "model = GPT2ForSequenceClassification.from_pretrained(\"gpt2\", num_labels=6)\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# The IMPORTANT BIT:\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a6f2ff",
   "metadata": {},
   "source": [
    "2. Load and Inspect the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f28c4a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'i didnt feel humiliated', 'label': 0}\n",
      "{'text': Value('string'), 'label': ClassLabel(names=['sadness', 'joy', 'love', 'anger', 'fear', 'surprise'])}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"dair-ai/emotion\")\n",
    "\n",
    "train_dataset = dataset[\"train\"]\n",
    "val_dataset = dataset[\"validation\"]\n",
    "test_dataset = dataset[\"test\"]\n",
    "\n",
    "print(train_dataset[0])  # See one example\n",
    "print(train_dataset.features)  # Output: {'text': ..., 'label': ...}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c069a09f",
   "metadata": {},
   "source": [
    "3. Tokenize the Text Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5176b07f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def preprocess(batch):\n",
    "    return tokenizer(batch[\"text\"], truncation=True, padding=\"max_length\", max_length=64)\n",
    "\n",
    "encoded_dataset = dataset.map(preprocess, batched=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d014f96",
   "metadata": {},
   "source": [
    "4. Evaluate the Foundation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80606ef9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [250/250 07:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.240687847137451, 'eval_accuracy': 0.285, 'eval_runtime': 424.1897, 'eval_samples_per_second': 4.715, 'eval_steps_per_second': 0.589}\n"
     ]
    }
   ],
   "source": [
    "# Create a compute_metrics function:\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return {\"accuracy\": accuracy_score(labels, predictions)}\n",
    "\n",
    "\n",
    "# Set up and run evaluation:\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"/tmp/gpt2-emotion\",\n",
    "    per_device_eval_batch_size=8,\n",
    "    no_cuda=True\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    eval_dataset=encoded_dataset[\"validation\"],\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "baseline_metrics = trainer.evaluate()\n",
    "print(baseline_metrics)\n",
    "\n",
    "\n",
    "\n",
    "##This establishes a baseline for model performance prior to adaptation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d52a229",
   "metadata": {},
   "source": [
    "## Performing Parameter-Efficient Fine-Tuning\n",
    "\n",
    "TODO: In the cells below, create a PEFT model from your loaded model, run a training loop, and save the PEFT model weights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1144cc45",
   "metadata": {},
   "source": [
    "1. Configure LoRA and Create a PEFT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "894046c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/peft/tuners/lora.py:475: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 304,128 || all params: 124,744,704 || trainable%: 0.24380032999236584\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=\"SEQ_CLS\"\n",
    ")\n",
    "peft_model = get_peft_model(model, lora_config)\n",
    "peft_model.print_trainable_parameters()  # Shows only LoRA params are trainable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42afe636",
   "metadata": {},
   "source": [
    "2. Fine-Tune the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b47abf88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2000' max='2000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2000/2000 02:41, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.154500</td>\n",
       "      <td>1.068019</td>\n",
       "      <td>0.619500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"/tmp/gpt2_peft\",\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=1,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    ")\n",
    "trainer = Trainer(\n",
    "    model=peft_model,\n",
    "    args=training_args,\n",
    "    train_dataset=encoded_dataset[\"train\"],\n",
    "    eval_dataset=encoded_dataset[\"validation\"],\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "trainer.train()\n",
    "peft_model.save_pretrained(\"/tmp/gpt2_peft_lora\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e8a663",
   "metadata": {},
   "source": [
    "###  ⚠️ IMPORTANT ⚠️\n",
    "\n",
    "Due to workspace storage constraints, you should not store the model weights in the same directory but rather use `/tmp` to avoid workspace crashes which are irrecoverable.\n",
    "Ensure you save it in /tmp always."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa7fe003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/tmp/model/tokenizer_config.json',\n",
       " '/tmp/model/special_tokens_map.json',\n",
       " '/tmp/model/vocab.json',\n",
       " '/tmp/model/merges.txt',\n",
       " '/tmp/model/added_tokens.json')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saving the model\n",
    "model.save_pretrained(\"/tmp/model\")\n",
    "tokenizer.save_pretrained(\"/tmp/model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615b12c6",
   "metadata": {},
   "source": [
    "## Performing Inference with a PEFT Model\n",
    "\n",
    "TODO: In the cells below, load the saved PEFT model weights and evaluate the performance of the trained PEFT model. Be sure to compare the results to the results from prior to fine-tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43ff4bf",
   "metadata": {},
   "source": [
    "1. Load the Fine-Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc3a8147",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import PeftModel\n",
    "\n",
    "peft_model = PeftModel.from_pretrained(model, \"/tmp/gpt2_peft_lora\")\n",
    "trainer = Trainer(\n",
    "    model=peft_model,\n",
    "    args=training_args,\n",
    "    eval_dataset=encoded_dataset[\"validation\"],\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce66de7f",
   "metadata": {},
   "source": [
    "2. Evaluate the Fine-Tuned Model and Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "866ab28c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [250/250 00:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline: {'eval_loss': 4.240687847137451, 'eval_accuracy': 0.285, 'eval_runtime': 424.1897, 'eval_samples_per_second': 4.715, 'eval_steps_per_second': 0.589}\n",
      "PEFT Fine-Tuned: {'eval_loss': 1.0680186748504639, 'eval_accuracy': 0.6195, 'eval_runtime': 8.8185, 'eval_samples_per_second': 226.796, 'eval_steps_per_second': 28.35}\n"
     ]
    }
   ],
   "source": [
    "peft_metrics = trainer.evaluate()\n",
    "print(\"Baseline:\", baseline_metrics)\n",
    "print(\"PEFT Fine-Tuned:\", peft_metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff42e353",
   "metadata": {},
   "source": [
    "The experiment shows that the original GPT-2 foundation model performs poorly at emotion classification (accuracy ≈ 28.5%). However, after applying LoRA-based parameter-efficient fine-tuning for just one epoch, validation accuracy rose to nearly 62%. This demonstrates the effectiveness of PEFT for adapting large language models to custom text classification tasks with minimal computational cost.\n",
    "\n",
    "Stage   \tAccuracy\tEval Loss\tWhat it means\n",
    "Baseline \t0.285   \t4.24     \tPretrained, not tuned for emotions—almost random\n",
    "PEFT LoRA \t0.6195   \t1.07    \tModel now specialized for emotion detection—good improvement!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
